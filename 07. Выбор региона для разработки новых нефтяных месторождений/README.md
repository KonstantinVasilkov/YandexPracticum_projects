# Предсказание вероятности оттока клиентов банка

### Использованные инструменты:
* Python
* Pandas
* Matplotlib
* машинное обучение
* math
* Seaborn
* sklearn

### Задача:
Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.
Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Нам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 

Надо постоить построить модель с предельно большим значением *F1*-меры. Нужно довести метрику до 0.59.

### Данные:
- `RowNumber` — индекс строки в данных
- `CustomerId` — уникальный идентификатор клиента
- `Surname` — фамилия
- `CreditScore` — кредитный рейтинг
- `Geography` — страна проживания
- `Gender` — пол
- `Age` — возраст
- `Tenure` — количество недвижимости у клиента
- `Balance` — баланс на счёте
- `NumOfProducts` — количество продуктов банка, используемых клиентом
- `HasCrCard` — наличие кредитной карты
- `IsActiveMember` — активность клиента
- `EstimatedSalary` — предполагаемая зарплата

Целевой признак:
- `Exited` — факт ухода клиента

### Описание проекта
* Спрогнозирована вероятность ухода клиента из банка в ближайшее время.
* Построена модель с предельно большим значением F1-меры с последующей проверкой на тестовой выборке. Доведена метрика до 0.63. 
* Дополнительно измерен AUC-ROC, соотнесен с F1-мерой.
* Обучение с учителем. Работа с несбалансированными данными.

### Краткий вывод:
* `Дерево решений` и `Случайный лес` дают более плохие предсказания на тестовой выборке, чем на валидационной и тренировочной.
* Тем не менее предсказательная сила этих моделей даже на тестовой выборке больше порога в 0.75. 
* `Логистичекая регрессия` дала гораздо более стабильный результат (+- 1%), но сама предсказательная сила модели в данном случае слабее, чем требуется по заданию.